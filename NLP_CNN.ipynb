{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5413275",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.model_selection import train_test_split\n",
    "from gensim.models import FastText\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Conv1D, GlobalMaxPooling1D, Concatenate, Dropout, Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "99c1c6c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Error loading stopwords: <urlopen error [WinError 10054]\n",
      "[nltk_data]     An existing connection was forcibly closed by the\n",
      "[nltk_data]     remote host>\n",
      "[nltk_data] Downloading package wordnet to C:\\Users\\eng\n",
      "[nltk_data]     abdulrhman\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Download necessary NLTK resources\n",
    "nltk.download(\"stopwords\")\n",
    "nltk.download(\"wordnet\")\n",
    "\n",
    "# Define stopwords and lemmatizer\n",
    "en_stop = set(stopwords.words(\"english\"))\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e141daa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"One of the other reviewers has mentioned that after watching just 1 Oz episode you'll be hooked. They are right, as this is exactly what happened with me.<br /><br />The first thing that struck me about Oz was its brutality and unflinching scenes of violence, which set in right from the word GO. Trust me, this is not a show for the faint hearted or timid. This show pulls no punches with regards to drugs, sex or violence. Its is hardcore, in the classic use of the word.<br /><br />It is called OZ as that is the nickname given to the Oswald Maximum Security State Penitentary. It focuses mainly on Emerald City, an experimental section of the prison where all the cells have glass fronts and face inwards, so privacy is not high on the agenda. Em City is home to many..Aryans, Muslims, gangstas, Latinos, Christians, Italians, Irish and more....so scuffles, death stares, dodgy dealings and shady agreements are never far away.<br /><br />I would say the main appeal of the show is due to the fact that it goes where other shows wouldn't dare. Forget pretty pictures painted for mainstream audiences, forget charm, forget romance...OZ doesn't mess around. The first episode I ever saw struck me as so nasty it was surreal, I couldn't say I was ready for it, but as I watched more, I developed a taste for Oz, and got accustomed to the high levels of graphic violence. Not just violence, but injustice (crooked guards who'll be sold out for a nickel, inmates who'll kill on order and get away with it, well mannered, middle class inmates being turned into prison bitches due to their lack of street skills or prison experience) Watching Oz, you may become comfortable with what is uncomfortable viewing....thats if you can get in touch with your darker side.\"\n",
      " 'A wonderful little production. <br /><br />The filming technique is very unassuming- very old-time-BBC fashion and gives a comforting, and sometimes discomforting, sense of realism to the entire piece. <br /><br />The actors are extremely well chosen- Michael Sheen not only \"has got all the polari\" but he has all the voices down pat too! You can truly see the seamless editing guided by the references to Williams\\' diary entries, not only is it well worth the watching but it is a terrificly written and performed piece. A masterful production about one of the great master\\'s of comedy and his life. <br /><br />The realism really comes home with the little things: the fantasy of the guard which, rather than use the traditional \\'dream\\' techniques remains solid then disappears. It plays on our knowledge and our senses, particularly with the scenes concerning Orton and Halliwell and the sets (particularly of their flat with Halliwell\\'s murals decorating every surface) are terribly well done.'\n",
      " 'I thought this was a wonderful way to spend time on a too hot summer weekend, sitting in the air conditioned theater and watching a light-hearted comedy. The plot is simplistic, but the dialogue is witty and the characters are likable (even the well bread suspected serial killer). While some may be disappointed when they realize this is not Match Point 2: Risk Addiction, I thought it was proof that Woody Allen is still fully in control of the style many of us have grown to love.<br /><br />This was the most I\\'d laughed at one of Woody\\'s comedies in years (dare I say a decade?). While I\\'ve never been impressed with Scarlet Johanson, in this she managed to tone down her \"sexy\" image and jumped right into a average, but spirited young woman.<br /><br />This may not be the crown jewel of his career, but it was wittier than \"Devil Wears Prada\" and more interesting than \"Superman\" a great comedy to go see with friends.'\n",
      " ...\n",
      " 'I am a Catholic taught in parochial elementary schools by nuns, taught by Jesuit priests in high school & college. I am still a practicing Catholic but would not be considered a \"good Catholic\" in the church\\'s eyes because I don\\'t believe certain things or act certain ways just because the church tells me to.<br /><br />So back to the movie...its bad because two people are killed by this nun who is supposed to be a satire as the embodiment of a female religious figurehead. There is no comedy in that and the satire is not done well by the over acting of Diane Keaton. I never saw the play but if it was very different from this movies then it may be good.<br /><br />At first I thought the gun might be a fake and the first shooting all a plan by the female lead of the four former students as an attempt to demonstrate Sister Mary\\'s emotional and intellectual bigotry of faith. But it turns out the bullets were real and the story has tragedy...the tragedy of loss of life (besides the two former students...the lives of the aborted babies, the life of the student\\'s mom), the tragedy of dogmatic authority over love of people, the tragedy of organized religion replacing true faith in God. This is what is wrong with today\\'s Islam, and yesterday\\'s Judaism and Christianity.'\n",
      " 'I\\'m going to have to disagree with the previous comment and side with Maltin on this one. This is a second rate, excessively vicious Western that creaks and groans trying to put across its central theme of the Wild West being tamed and kicked aside by the steady march of time. It would like to be in the tradition of \"Butch Cassidy and the Sundance Kid\", but lacks that film\\'s poignancy and charm. Andrew McLaglen\\'s direction is limp, and the final 30 minutes or so are a real botch, with some incomprehensible strategy on the part of heroes Charlton Heston and Chris Mitchum. (Someone give me a holler if you can explain to me why they set that hillside on fire.) There was something callous about the whole treatment of the rape scene, and the woman\\'s reaction afterwards certainly did not ring true. Coburn is plenty nasty as the half breed escaped convict out for revenge, but all of his fellow escapees are underdeveloped (they\\'re like bowling pins to be knocked down one by one as the story lurches forward). Michael Parks gives one of his typically shifty, lethargic, mumbling performances, but in this case it was appropriate as his modern style sheriff symbolizes the complacency that technological progress can bring about.'\n",
      " \"No one expects the Star Trek movies to be high art, but the fans do expect a movie that is as good as some of the best episodes. Unfortunately, this movie had a muddled, implausible plot that just left me cringing - this is by far the worst of the nine (so far) movies. Even the chance to watch the well known characters interact in another movie can't save this movie - including the goofy scenes with Kirk, Spock and McCoy at Yosemite.<br /><br />I would say this movie is not worth a rental, and hardly worth watching, however for the True Fan who needs to see all the movies, renting this movie is about the only way you'll see it - even the cable channels avoid this movie.\"]\n",
      "[1 1 1 ... 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# ------------------ LOAD DATA ------------------\n",
    "df = pd.read_csv(r\"C:\\Users\\eng abdulrhman\\Downloads\\IMDB Dataset.csv\\IMDB Dataset.csv\")\n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1, 'negative': 0})\n",
    "texts = df['review'].values\n",
    "labels = df['sentiment'].values\n",
    "\n",
    "print(texts)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "541e32f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------ TEXT CLEANING ------------------\n",
    "def preprocess_text(text):\n",
    "    text = text.lower()  # Convert to lowercase\n",
    "    text = re.sub(r\"[^a-zA-Z\\s]\", \"\", text)  # Remove numbers and special characters\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()  # Remove extra spaces\n",
    "\n",
    "    words = text.split()  # Word tokenization\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if len(word) > 3 and word not in en_stop]\n",
    "    return words  # Return list of words (FastText expects list format)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3be7a842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply preprocessing\n",
    "tokenized_texts = [preprocess_text(text) for text in texts]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e03c8460",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "# ------------------- 3. Train FastText -------------------\n",
    "embedding_dim = 100\n",
    "# Step 1: Train FastText Model on IMDB Data\n",
    "fasttext_model = FastText(vector_size=embedding_dim, window=5, min_count=5, workers=4, sg=1, epochs=10)\n",
    "fasttext_model.build_vocab(corpus_iterable=tokenized_texts)\n",
    "fasttext_model.train(corpus_iterable=tokenized_texts, total_examples=len(tokenized_texts), epochs=10)\n",
    "fasttext_model.save(\"IMDB_fasttext.model\")\n",
    "print(\"Model trained and saved successfully.\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "548c8224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ------------------- 4. Prepare Embedding Matrix -------------------\n",
    "max_len = 200\n",
    "def sentence_to_embedding_matrix(tokens):\n",
    "    matrix = []\n",
    "    for i in range(max_len):\n",
    "        if i < len(tokens):\n",
    "            word = tokens[i]\n",
    "            matrix.append(fasttext_model.wv[word] if word in fasttext_model.wv else np.zeros(embedding_dim))\n",
    "        else:\n",
    "            matrix.append(np.zeros(embedding_dim))  # padding\n",
    "    return matrix\n",
    "\n",
    "X = np.array([sentence_to_embedding_matrix(sentence) for sentence in tokenized_texts])\n",
    "y = np.array(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3ff76457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 200, 100)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9114868a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_model(kernel_sizes):\n",
    "    input_layer = Input(shape=(max_len, embedding_dim))\n",
    "    \n",
    "    convs = []\n",
    "    for k in kernel_sizes:\n",
    "        conv1 = GlobalMaxPooling1D()(Conv1D(100, k, activation='relu')(input_layer))\n",
    "        conv2 = GlobalMaxPooling1D()(Conv1D(100, k, activation='relu')(input_layer))\n",
    "        convs.extend([conv1, conv2])  # Add both filters\n",
    "\n",
    "    merged = Concatenate()(convs)\n",
    "    dropout = Dropout(0.5)(merged)  # Prevent overfitting\n",
    "    output = Dense(1, activation='sigmoid')(dropout)\n",
    "\n",
    "    model = Model(inputs=input_layer, outputs=output)\n",
    "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df6ecb7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with kernel sizes: [2, 3, 4]\n",
      "Test loss: 0.2497 | Test accuracy: 0.9016\n",
      "\n",
      "Training with kernel sizes: [3, 4, 5]\n",
      "Test loss: 0.2582 | Test accuracy: 0.8997\n",
      "\n",
      "Training with kernel sizes: [4, 5, 6]\n",
      "Test loss: 0.2628 | Test accuracy: 0.8991\n",
      "\n",
      "Best kernel set: [2, 3, 4] with test accuracy: 0.9016\n"
     ]
    }
   ],
   "source": [
    "# ---------------- 5. Train and evaluate models with different kernel sizes ----------------\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "kernel_sets = [[2, 3, 4], [3, 4, 5], [4, 5, 6]]\n",
    "\n",
    "best_acc = 0\n",
    "best_kernels = None\n",
    "\n",
    "for kernels in kernel_sets:\n",
    "    print(f\"\\nTraining with kernel sizes: {kernels}\")\n",
    "    model = cnn_model(kernels)\n",
    "    model.fit(X_train, y_train, epochs=10, batch_size=128, validation_split=0.1, verbose=0)\n",
    "    \n",
    "    loss, acc = model.evaluate(X_test, y_test, verbose=0)\n",
    "    print(f\"Test loss: {loss:.4f} | Test accuracy: {acc:.4f}\")\n",
    "    \n",
    "    if acc > best_acc:\n",
    "        best_acc = acc\n",
    "        best_kernels = kernels\n",
    "\n",
    "print(f\"\\nBest kernel set: {best_kernels} with test accuracy: {best_acc:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
